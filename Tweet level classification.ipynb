{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb735afb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "import glob\n",
    "from preprocessor import api as tweet_preprocessor\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "\n",
    "from pyspark.sql.functions import col, udf, to_timestamp, lit, to_timestamp, when, rand\n",
    "from pyspark.sql.types import IntegerType, LongType, DoubleType, StringType, ArrayType\n",
    "from pyspark.ml.feature import Normalizer, StandardScaler, MinMaxScaler, VectorAssembler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Dense, Input, concatenate, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.losses import MeanSquaredError, CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e3ba2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f570fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "bot_tweets_dataset_path = 'F://TwitterBotDataset//tweet_dataset_small//bot_tweets//'\n",
    "genuine_tweets_dataset_path = 'F://TwitterBotDataset//tweet_dataset_small//genuine_tweets//'\n",
    "COLUMN_NAMES = ['text', 'retweet_count', 'reply_count', 'favorite_count',\n",
    "                'num_hashtags', 'num_urls', 'num_mentions']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "468479f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "conf.setMaster(\"local[8]\").setAppName(\"ml_account_ base_session\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# init spark\n",
    "#spark = SparkSession.builder.appName('ml_account_ base_session').getOrCreate()\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bfda832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-SRLISO7:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ml_account_ base_session</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1a2ef5d51e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2764e226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99999 199999\n"
     ]
    }
   ],
   "source": [
    "# read dataset from csv\n",
    "def read_dataset():\n",
    "    bot_tweets = spark.read.csv(bot_tweets_dataset_path, header = True, inferSchema = True)\n",
    "    genuine_tweets = spark.read.csv(genuine_tweets_dataset_path, header = True, inferSchema = True)\n",
    "    return bot_tweets, genuine_tweets\n",
    "\n",
    "bot_tweets_df, genuine_tweets_df = read_dataset()\n",
    "\n",
    "print(bot_tweets_df.count(), genuine_tweets_df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04baa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column name of dataframe\n",
    "column_name = [cname for cname, tp in bot_tweets_df.dtypes]\n",
    "len(column_name), len(genuine_tweets_df.dtypes)\n",
    "#column_name\n",
    "\n",
    "#Number of column is diffrent for bot and genuine tweets data\n",
    "\n",
    "#genuine_tweets_df = genuine_tweets_df.toDF(*column_name)\n",
    "genuine_tweets_df = genuine_tweets_df.toDF('id','text','source','user_id','truncated','in_reply_to_status_id', \n",
    "                                           'in_reply_to_user_id','in_reply_to_screen_name', 'retweeted_status_id',\n",
    "                                           'geo','place','contributors','retweet_count', 'reply_count','favorite_count',\n",
    "                                           'favorited', 'retweeted','possibly_sensitive','num_hashtags','num_urls',\n",
    "                                           'num_mentions','created_at','timestamp','crawled_at', 'updated', \"last_one\")\n",
    "genuine_tweets_df = genuine_tweets_df.drop('created_at') # remove 5th column from end\n",
    "\n",
    "#update column name according to \n",
    "genuine_tweets_df = genuine_tweets_df.toDF('id','text','source','user_id','truncated','in_reply_to_status_id', \n",
    "                                           'in_reply_to_user_id','in_reply_to_screen_name', 'retweeted_status_id',\n",
    "                                           'geo','place','contributors','retweet_count', 'reply_count','favorite_count',\n",
    "                                           'favorited', 'retweeted','possibly_sensitive','num_hashtags','num_urls',\n",
    "                                           'num_mentions','created_at','timestamp','crawled_at', 'updated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43fb48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same column has diffrent data type. So make data type same for every column\n",
    "genuine_tweets_df = genuine_tweets_df.withColumn(\"id\",col(\"id\").cast(IntegerType())) \\\n",
    "                                .withColumn(\"favorite_count\",col(\"favorite_count\").cast(LongType())) \\\n",
    "                                .withColumn(\"favorited\",col(\"favorited\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa4c6c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99999 99999\n"
     ]
    }
   ],
   "source": [
    "print(bot_tweets_df.count(), bot_tweets_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e3ad49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## only keep the required column from the dataframe\n",
    "bot_tweets_df = bot_tweets_df.select(*COLUMN_NAMES)\n",
    "genuine_tweets_df = genuine_tweets_df.select(*COLUMN_NAMES)\n",
    "\n",
    "## add BotOrNot column\n",
    "bot_tweets_df = bot_tweets_df.withColumn('BotOrNot', lit(1))\n",
    "genuine_tweets_df = genuine_tweets_df.withColumn('BotOrNot', lit(0))\n",
    "\n",
    "#combine clean and bot accounts data togather\n",
    "tweets_df = bot_tweets_df.union(genuine_tweets_df)\n",
    "\n",
    "# shuffle dataset\n",
    "tweets_df = tweets_df.orderBy(rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd336307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299998\n"
     ]
    }
   ],
   "source": [
    "print(tweets_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eb8c846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text', 'string'),\n",
       " ('retweet_count', 'string'),\n",
       " ('reply_count', 'string'),\n",
       " ('favorite_count', 'bigint'),\n",
       " ('num_hashtags', 'string'),\n",
       " ('num_urls', 'string'),\n",
       " ('num_mentions', 'string'),\n",
       " ('BotOrNot', 'int')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c41b995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(text='So what is Bitcoin and the Bitcoin block chain exactly? http://t.co/OmjqcnvPdP', retweet_count='2', reply_count='0', favorite_count=0, num_hashtags='0', num_urls='1', num_mentions='0', BotOrNot=0),\n",
       " Row(text='Check out these alternatives to traditional beef hamburgers!  http://t.co/HlLcXvUpYA', retweet_count='0', reply_count='0', favorite_count=0, num_hashtags='0', num_urls='1', num_mentions='0', BotOrNot=0),\n",
       " Row(text=\"Every homie ain't ya homie boy I thought you knew ? http://t.co/ZsJr5BWvmk\", retweet_count='0', reply_count='0', favorite_count=0, num_hashtags='0', num_urls='1', num_mentions='0', BotOrNot=1),\n",
       " Row(text='It really rains on your parade when you get nachos and the cheese is cold.', retweet_count='0', reply_count='0', favorite_count=0, num_hashtags='0', num_urls='0', num_mentions='0', BotOrNot=1),\n",
       " Row(text='Where there is an open mind, there will always be a frontier. - Charles F. Kettering', retweet_count='0', reply_count='0', favorite_count=0, num_hashtags='0', num_urls='0', num_mentions='0', BotOrNot=0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c69d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process each partition of data in each worker node\n",
    "\n",
    "# def preocessTextColumn(df, column_name, new_column_name):\n",
    "#     values = df.select(column_name).collect()\n",
    "#     values = [tweet_preprocessor.tokenize(row_val.text) for row_val in values]\n",
    "#     print(type(values))\n",
    "#     print(values[:5])\n",
    "#     return df\n",
    "\n",
    "text_process_udf = udf(lambda x : tweet_preprocessor.tokenize(x), StringType())\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = df.withColumn('text', text_process_udf(df.text))\n",
    "    df = df.withColumn(\"retweet_count\",col(\"retweet_count\").cast(DoubleType()))\n",
    "    df = df.withColumn(\"reply_count\",col(\"reply_count\").cast(DoubleType()))\n",
    "    df = df.withColumn(\"favorite_count\",col(\"favorite_count\").cast(DoubleType()))\n",
    "    df = df.withColumn(\"num_hashtags\",col(\"num_hashtags\").cast(DoubleType()))\n",
    "    df = df.withColumn(\"num_urls\",col(\"num_urls\").cast(DoubleType()))\n",
    "    df = df.withColumn(\"num_mentions\",col(\"num_mentions\").cast(DoubleType()))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# def preprocess_data2(df):\n",
    "#         df_rdd = df.rdd.map(lambda x: (tweet_preprocessor.tokenize(x.text), x.retweet_count, x.reply_count, x.favorite_count,\n",
    "#                                        x.num_hashtags, x.num_urls, x.num_mentions, x.BotOrNot))\n",
    "#         df = df_rdd.toDF()\n",
    "#         return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "271a119c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = preprocess_data(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29829a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- retweet_count: double (nullable = true)\n",
      " |-- reply_count: double (nullable = true)\n",
      " |-- favorite_count: double (nullable = true)\n",
      " |-- num_hashtags: double (nullable = true)\n",
      " |-- num_urls: double (nullable = true)\n",
      " |-- num_mentions: double (nullable = true)\n",
      " |-- BotOrNot: integer (nullable = false)\n",
      "\n",
      "Total Tweets: 299998 \n",
      "Type: <class 'pyspark.sql.dataframe.DataFrame'> \n",
      "dataschema: None\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Tweets: {} \\nType: {} \\ndataschema: {}\".format(tweets_df.count(), type(tweets_df), tweets_df.printSchema()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90dfda89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'retweet_count', 'reply_count', 'favorite_count', 'num_hashtags', 'num_urls', 'num_mentions', 'BotOrNot']\n"
     ]
    }
   ],
   "source": [
    "print(tweets_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "282c9196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(text='So what is Bitcoin and the Bitcoin block chain exactly? <URL>', retweet_count=2.0, reply_count=0.0, favorite_count=0.0, num_hashtags=0.0, num_urls=1.0, num_mentions=0.0, BotOrNot=0),\n",
       " Row(text='Check out these alternatives to traditional beef hamburgers! <URL>', retweet_count=0.0, reply_count=0.0, favorite_count=0.0, num_hashtags=0.0, num_urls=1.0, num_mentions=0.0, BotOrNot=0),\n",
       " Row(text=\"Every homie ain't ya homie boy I thought you knew ? <URL>\", retweet_count=0.0, reply_count=0.0, favorite_count=0.0, num_hashtags=0.0, num_urls=1.0, num_mentions=0.0, BotOrNot=1),\n",
       " Row(text='It really rains on your parade when you get nachos and the cheese is cold.', retweet_count=0.0, reply_count=0.0, favorite_count=0.0, num_hashtags=0.0, num_urls=0.0, num_mentions=0.0, BotOrNot=1),\n",
       " Row(text='Where there is an open mind, there will always be a frontier. - Charles F. Kettering', retweet_count=0.0, reply_count=0.0, favorite_count=0.0, num_hashtags=0.0, num_urls=0.0, num_mentions=0.0, BotOrNot=0)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4095423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn a line of text into d dimentional vector \n",
    "GLOVE_DIR = \"C://Users//USER//projects//\"\n",
    "\n",
    "def makeGloveWordEmbedder(glove_path):\n",
    "    embedding_dict = {}\n",
    "    with open(glove_path, 'r', encoding=\"utf-8\") as glove_file:\n",
    "        for line in glove_file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embedding_dict[word] = vector\n",
    "            \n",
    "    return embedding_dict        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57ce8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create word embedding GLoVE model dictionary. Use pre trained model\n",
    "\n",
    "text_feature_dimention = 25\n",
    "glove_word2vec_embedder = makeGloveWordEmbedder(GLOVE_DIR + \"glove.twitter.27B.25d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42392591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5541   ,  0.055494 ,  0.0036707, -0.14801  ,  0.86527  ,\n",
       "       -0.44493  ,  0.19887  ,  0.60156  ,  0.71646  ,  0.16747  ,\n",
       "        0.86978  , -0.53673  , -3.2188   , -0.97591  ,  0.020251 ,\n",
       "        0.31074  ,  0.22997  ,  0.65166  , -0.19235  , -0.61838  ,\n",
       "       -0.17933  , -1.7447   , -0.56918  , -0.4337   , -0.47025  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_word2vec_embedder[\"google\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4e0eb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give a word and get that word representing feature vector of dimention 25 from embedding dictionary\n",
    "def word2vec(word_dict=None, word=None, dim=25):\n",
    "    default_vector = np.zeros(dim)\n",
    "    \n",
    "    if word_dict is None or word is None:\n",
    "        return default_vector\n",
    "    \n",
    "    word_vector = word_dict.get(word)\n",
    "    \n",
    "    if word_vector is None:\n",
    "        return default_vector\n",
    "    return word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65722218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> [ 1.3429    0.32133   0.24542   0.070143  0.73769  -0.1736    0.63438\n",
      "  1.571    -0.88553   0.326    -0.31173  -0.067133 -3.6154   -0.38971\n",
      " -0.31431   1.3033    0.31316  -0.90273  -1.9166   -0.5154    0.51635\n",
      " -0.54521  -0.3446    0.45339  -1.0241  ]\n"
     ]
    }
   ],
   "source": [
    "# test a word representing feature vector\n",
    "word_vector = word2vec(glove_word2vec_embedder, \"tweet\", text_feature_dimention)\n",
    "print(type(word_vector), word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02e1680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# LSTM + Dense layer model\n",
    "def lstm_model(input_dim, output_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(LSTM(64, input_shape=(input_dim,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(output_dim))\n",
    "    return model\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "def lstm_model(input_dim, output_dim):\n",
    "    lstm_model = LSTM(32, input_shape=(input_dim,1), return_sequences=True, return_state=True)\n",
    "    return lstm_model\n",
    "'''\n",
    "\n",
    "'''\n",
    "def reset_weights(model):\n",
    "    session = tf.keras.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel_initializer'):\n",
    "            layer.kernel.initializer.run(session=session)\n",
    "'''\n",
    "\n",
    "#----------------LSTM Model----------------------\n",
    "\n",
    "#create a 1 layer LSTM model\n",
    "#input dimention: 3d (1,7,25) input_sample = [[[1,...,25]],..,[1,...,25]]\n",
    "#output dimention: 1d (1,32) output_sample [[1,2,3,,,,32]]\n",
    "def lstm_model(output_dim):\n",
    "    model = LSTM(output_dim, return_sequences=False, return_state=False)\n",
    "    return model\n",
    "\n",
    "def reset_lstm_model(model):\n",
    "    model.resate_states() # stateful=True is required for reset states\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d703d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm = lstm_model(input_dim=25, output_dim=32)\n",
    "# lstm.summary()\n",
    "\n",
    "# lstm.compile(\n",
    "#     loss=CategoricalCrossentropy(),\n",
    "#     optimizer=\"adam\",\n",
    "#     metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18c1fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create LSTM model of output dimention 32. Model output feature vector will be of 32 dimention vector\n",
    "lstm = lstm_model(32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "775f8717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convver a sentence to a feature vector using LSTM(RNN) model\n",
    "def sent2vec(sent):\n",
    "    words = sent.split(' ')\n",
    "    word_vectors = np.array([])\n",
    "    count = 0;\n",
    "    for word in words:\n",
    "        word_vector = word2vec(glove_word2vec_embedder, word)\n",
    "        print(\"word dim: {}\".format(len(word_vector)))\n",
    "        if word_vectors.size == 0:\n",
    "            word_vectors = np.array([word_vector])\n",
    "        else:\n",
    "            word_vectors = np.vstack([word_vectors, word_vector])\n",
    "        count = count + 1\n",
    "    \n",
    "    print(\"Input feature vector shape before reshape(2D): {}\".format(word_vectors.shape))\n",
    "        \n",
    "    input_feature_vectors = np.reshape(word_vectors, (1, count, text_feature_dimention))\n",
    "    print(\"Input feature vector shape after reshape(3d): {}\".format(input_feature_vectors.shape))\n",
    "    print(\"LSTM requirs 3d shape inputs [batch, timesteps, feature]\")\n",
    "    output_vector = lstm(input_feature_vectors)\n",
    "#     lstm.reset_states() # stateful = True is required for reset\n",
    "\n",
    "    print(\"result vector shape: {}\".format(output_vector.shape))\n",
    "    print(\"Last input was: {}\".format(input_feature_vectors[0][-1]))\n",
    "    print(\"output result: {}\".format(output_vector))\n",
    "    \n",
    "    # (tensore --> numpy 0bject --> numpy.array --> array/list/ArrayType)\n",
    "    return output_vector.numpy()[0].tolist() \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3c8bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------\n",
    "# Save code for reuse\n",
    "# input_feature_vectors = np.reshape(input_feature_vectors, (1, count, 25))\n",
    "# print(input_feature_vectors)\n",
    "# lstm = LSTM(32, return_sequences=True, return_state=True, stateful=True)\n",
    "# whole_seq_output, final_memory_state, final_carry_state = lstm(input_feature_vectors)\n",
    "##-----------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "994cdf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word dim: 25\n",
      "word dim: 25\n",
      "word dim: 25\n",
      "word dim: 25\n",
      "word dim: 25\n",
      "word dim: 25\n",
      "word dim: 25\n",
      "Input feature vector shape before reshape(2D): (7, 25)\n",
      "Input feature vector shape after reshape(3d): (1, 7, 25)\n",
      "LSTM requirs 3d shape inputs [batch, timesteps, feature]\n",
      "result vector shape: (1, 32)\n",
      "Last input was: [ 0.52543998  0.81762999 -0.33526    -1.08469999  1.34399998 -0.76054001\n",
      "  0.35901001 -0.14561     1.23880005  0.063683   -0.085714   -0.1045\n",
      " -3.53110003  0.0064582   0.44380999  0.58358997 -0.050973    0.25244999\n",
      "  0.57172     0.22875001 -0.27950999 -1.24839997 -0.36148    -0.60921001\n",
      " -0.61317998]\n",
      "output result: [[ 0.45467544  0.27176714 -0.09925152 -0.25991294  0.1314513   0.06059496\n",
      "   0.07321241 -0.37092263 -0.13981614  0.18063284  0.22067295  0.06147751\n",
      "   0.0376804  -0.07965042  0.06123774 -0.16793038  0.24811278 -0.17758675\n",
      "   0.15323628 -0.01909693 -0.15135057  0.24262711 -0.31437188 -0.13134502\n",
      "  -0.2592779   0.3224458  -0.24764483 -0.4268025  -0.42393532  0.261188\n",
      "   0.25213882  0.2877271 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " [0.45467543601989746,\n",
       "  0.27176713943481445,\n",
       "  -0.09925151616334915,\n",
       "  -0.2599129378795624,\n",
       "  0.1314512938261032,\n",
       "  0.060594964772462845,\n",
       "  0.07321241497993469,\n",
       "  -0.37092262506484985,\n",
       "  -0.13981613516807556,\n",
       "  0.1806328445672989,\n",
       "  0.22067295014858246,\n",
       "  0.06147750839591026,\n",
       "  0.03768039867281914,\n",
       "  -0.07965042442083359,\n",
       "  0.061237744987010956,\n",
       "  -0.16793037950992584,\n",
       "  0.2481127828359604,\n",
       "  -0.17758674919605255,\n",
       "  0.1532362848520279,\n",
       "  -0.019096925854682922,\n",
       "  -0.15135057270526886,\n",
       "  0.2426271140575409,\n",
       "  -0.31437188386917114,\n",
       "  -0.1313450187444687,\n",
       "  -0.25927790999412537,\n",
       "  0.322445809841156,\n",
       "  -0.2476448267698288,\n",
       "  -0.42680248618125916,\n",
       "  -0.42393532395362854,\n",
       "  0.26118800044059753,\n",
       "  0.25213882327079773,\n",
       "  0.28772708773612976])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"Twitter is a large social media network\"\n",
    "\n",
    "res_vector = sent2vec(sent)\n",
    "type(res_vector), res_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e167a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text string --> vector 32 dimention\n",
    "sent_to_vector_udf = udf(lambda x : sent2vec(x), ArrayType(DoubleType()))\n",
    "def processTextColumn(df, column_name, new_column_name):\n",
    "    df = df.withColumn(new_column_name, sent_to_vector_udf(col(column_name)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "373f0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_updated_column = 'text_features'\n",
    "tweets_df = processTextColumn(tweets_df, \"text\", text_updated_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2400d241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- retweet_count: double (nullable = true)\n",
      " |-- reply_count: double (nullable = true)\n",
      " |-- favorite_count: double (nullable = true)\n",
      " |-- num_hashtags: double (nullable = true)\n",
      " |-- num_urls: double (nullable = true)\n",
      " |-- num_mentions: double (nullable = true)\n",
      " |-- BotOrNot: integer (nullable = false)\n",
      " |-- text_features: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n",
      "299998 <class 'pyspark.sql.dataframe.DataFrame'> None\n"
     ]
    }
   ],
   "source": [
    "print(tweets_df.count(), type(tweets_df), tweets_df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47bba901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(text='So what is Bitcoin and the Bitcoin block chain exactly? <URL>', retweet_count=2.0, reply_count=0.0, favorite_count=0.0, num_hashtags=0.0, num_urls=1.0, num_mentions=0.0, BotOrNot=0, text_features=[0.28481611609458923, 0.21882453560829163, 0.06194785609841347, -0.3682086169719696, 0.262920618057251, 0.21629296243190765, 0.015426518395543098, -0.2468055635690689, -0.14578208327293396, 0.2106577306985855, 0.24197855591773987, -0.08361523598432541, 0.09170368313789368, 0.08617748320102692, 0.026449576020240784, -0.05779039487242699, 0.2882993221282959, -0.08279384672641754, 0.24426540732383728, -0.150812566280365, -0.14580199122428894, 0.07274134457111359, -0.2563191056251526, -0.2306952327489853, -0.18770168721675873, 0.13491402566432953, 0.05788596719503403, -0.22538118064403534, -0.1378612518310547, 0.13252323865890503, 0.1744457334280014, 0.1887575387954712]),\n",
       " Row(text='Check out these alternatives to traditional beef hamburgers! <URL>', retweet_count=0.0, reply_count=0.0, favorite_count=0.0, num_hashtags=0.0, num_urls=1.0, num_mentions=0.0, BotOrNot=0, text_features=[0.3195931315422058, 0.19706468284130096, 0.03314067795872688, -0.3947567045688629, 0.254959374666214, 0.23158355057239532, 0.0764976367354393, -0.20055817067623138, -0.173841193318367, 0.2155158966779709, 0.19657807052135468, -0.11714870482683182, 0.1662881076335907, 0.005150272510945797, 0.022258605808019638, -0.04357261583209038, 0.26955804228782654, -0.12863390147686005, 0.23878857493400574, -0.2516402006149292, -0.2215471863746643, 0.1429288536310196, -0.11087437719106674, -0.29234302043914795, -0.011042486876249313, 0.25159895420074463, 0.004114886745810509, -0.19354446232318878, -0.18695129454135895, -0.08782842755317688, 0.22144319117069244, 0.034857895225286484])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd353c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- retweet_count: double (nullable = true)\n",
      " |-- reply_count: double (nullable = true)\n",
      " |-- favorite_count: double (nullable = true)\n",
      " |-- num_hashtags: double (nullable = true)\n",
      " |-- num_urls: double (nullable = true)\n",
      " |-- num_mentions: double (nullable = true)\n",
      " |-- BotOrNot: integer (nullable = false)\n",
      " |-- text_features: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8707ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "columns = ['retweet_count', 'reply_count', 'favorite_count',\n",
    "           'num_hashtags' ,'num_urls', 'num_mentions', 'BotOrNot']\n",
    "\n",
    "tweets_df = tweets_df.select(*columns, \n",
    "                      tweets_df.text_features[0], tweets_df.text_features[1], tweets_df.text_features[2],tweets_df.text_features[3], tweets_df.text_features[4],\n",
    "                      tweets_df.text_features[5], tweets_df.text_features[6], tweets_df.text_features[7],tweets_df.text_features[8], tweets_df.text_features[9], \n",
    "                      tweets_df.text_features[10], tweets_df.text_features[11], tweets_df.text_features[12],tweets_df.text_features[13], tweets_df.text_features[14],\n",
    "                      tweets_df.text_features[15], tweets_df.text_features[16], tweets_df.text_features[17],tweets_df.text_features[18], tweets_df.text_features[19],\n",
    "                      tweets_df.text_features[20], tweets_df.text_features[21], tweets_df.text_features[22],tweets_df.text_features[23], tweets_df.text_features[24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb80116d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- retweet_count: double (nullable = true)\n",
      " |-- reply_count: double (nullable = true)\n",
      " |-- favorite_count: double (nullable = true)\n",
      " |-- num_hashtags: double (nullable = true)\n",
      " |-- num_urls: double (nullable = true)\n",
      " |-- num_mentions: double (nullable = true)\n",
      " |-- BotOrNot: integer (nullable = false)\n",
      " |-- text_features[0]: double (nullable = true)\n",
      " |-- text_features[1]: double (nullable = true)\n",
      " |-- text_features[2]: double (nullable = true)\n",
      " |-- text_features[3]: double (nullable = true)\n",
      " |-- text_features[4]: double (nullable = true)\n",
      " |-- text_features[5]: double (nullable = true)\n",
      " |-- text_features[6]: double (nullable = true)\n",
      " |-- text_features[7]: double (nullable = true)\n",
      " |-- text_features[8]: double (nullable = true)\n",
      " |-- text_features[9]: double (nullable = true)\n",
      " |-- text_features[10]: double (nullable = true)\n",
      " |-- text_features[11]: double (nullable = true)\n",
      " |-- text_features[12]: double (nullable = true)\n",
      " |-- text_features[13]: double (nullable = true)\n",
      " |-- text_features[14]: double (nullable = true)\n",
      " |-- text_features[15]: double (nullable = true)\n",
      " |-- text_features[16]: double (nullable = true)\n",
      " |-- text_features[17]: double (nullable = true)\n",
      " |-- text_features[18]: double (nullable = true)\n",
      " |-- text_features[19]: double (nullable = true)\n",
      " |-- text_features[20]: double (nullable = true)\n",
      " |-- text_features[21]: double (nullable = true)\n",
      " |-- text_features[22]: double (nullable = true)\n",
      " |-- text_features[23]: double (nullable = true)\n",
      " |-- text_features[24]: double (nullable = true)\n",
      "\n",
      "['retweet_count', 'reply_count', 'favorite_count', 'num_hashtags', 'num_urls', 'num_mentions', 'BotOrNot', 'text_features[0]', 'text_features[1]', 'text_features[2]', 'text_features[3]', 'text_features[4]', 'text_features[5]', 'text_features[6]', 'text_features[7]', 'text_features[8]', 'text_features[9]', 'text_features[10]', 'text_features[11]', 'text_features[12]', 'text_features[13]', 'text_features[14]', 'text_features[15]', 'text_features[16]', 'text_features[17]', 'text_features[18]', 'text_features[19]', 'text_features[20]', 'text_features[21]', 'text_features[22]', 'text_features[23]', 'text_features[24]'] 299998 None\n"
     ]
    }
   ],
   "source": [
    "print(tweets_df.columns, len(tweets_df.collect()), tweets_df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a28b769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare inpute feature vectors for DenseModel\n",
    "# tweets_df = tweets_df.drop('text')\n",
    "# tweets_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5fd49a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove \n",
    "\n",
    "feature_columns = ['retweet_count','reply_count','favorite_count','num_hashtags','num_urls','num_mentions',\n",
    "                   'text_features[0]','text_features[1]', 'text_features[2]','text_features[3]','text_features[4]',\n",
    "                   'text_features[5]','text_features[6]','text_features[7]', 'text_features[8]','text_features[9]',\n",
    "                   'text_features[10]','text_features[11]','text_features[12]','text_features[13]','text_features[14]',\n",
    "                   'text_features[15]','text_features[16]','text_features[17]','text_features[18]','text_features[19]',\n",
    "                   'text_features[20]','text_features[21]','text_features[22]', 'text_features[23]', 'text_features[24]']\n",
    "\n",
    "tweets_df = tweets_df.na.fill(value=0.0 ,subset= feature_columns)\n",
    "feature_assembler = VectorAssembler(inputCols = feature_columns, outputCol = 'independent_features')\n",
    "\n",
    "tweets_updated_df = feature_assembler.transform(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe4790ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- retweet_count: double (nullable = false)\n",
      " |-- reply_count: double (nullable = false)\n",
      " |-- favorite_count: double (nullable = false)\n",
      " |-- num_hashtags: double (nullable = false)\n",
      " |-- num_urls: double (nullable = false)\n",
      " |-- num_mentions: double (nullable = false)\n",
      " |-- BotOrNot: integer (nullable = false)\n",
      " |-- text_features[0]: double (nullable = false)\n",
      " |-- text_features[1]: double (nullable = false)\n",
      " |-- text_features[2]: double (nullable = false)\n",
      " |-- text_features[3]: double (nullable = false)\n",
      " |-- text_features[4]: double (nullable = false)\n",
      " |-- text_features[5]: double (nullable = false)\n",
      " |-- text_features[6]: double (nullable = false)\n",
      " |-- text_features[7]: double (nullable = false)\n",
      " |-- text_features[8]: double (nullable = false)\n",
      " |-- text_features[9]: double (nullable = false)\n",
      " |-- text_features[10]: double (nullable = false)\n",
      " |-- text_features[11]: double (nullable = false)\n",
      " |-- text_features[12]: double (nullable = false)\n",
      " |-- text_features[13]: double (nullable = false)\n",
      " |-- text_features[14]: double (nullable = false)\n",
      " |-- text_features[15]: double (nullable = false)\n",
      " |-- text_features[16]: double (nullable = false)\n",
      " |-- text_features[17]: double (nullable = false)\n",
      " |-- text_features[18]: double (nullable = false)\n",
      " |-- text_features[19]: double (nullable = false)\n",
      " |-- text_features[20]: double (nullable = false)\n",
      " |-- text_features[21]: double (nullable = false)\n",
      " |-- text_features[22]: double (nullable = false)\n",
      " |-- text_features[23]: double (nullable = false)\n",
      " |-- text_features[24]: double (nullable = false)\n",
      " |-- independent_features: vector (nullable = true)\n",
      "\n",
      "299998 <class 'pyspark.sql.dataframe.DataFrame'> None\n"
     ]
    }
   ],
   "source": [
    "#check\n",
    "num = len(tweets_updated_df.collect())\n",
    "print(num, type(tweets_updated_df), tweets_updated_df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f017b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+--------------+------------+--------+------------+--------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+-------------------+-------------------+--------------------+-------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|retweet_count|reply_count|favorite_count|num_hashtags|num_urls|num_mentions|BotOrNot|   text_features[0]|   text_features[1]|    text_features[2]|   text_features[3]|   text_features[4]|   text_features[5]|    text_features[6]|    text_features[7]|    text_features[8]|   text_features[9]|  text_features[10]|   text_features[11]|  text_features[12]|   text_features[13]|   text_features[14]|   text_features[15]|  text_features[16]|   text_features[17]|  text_features[18]|   text_features[19]|   text_features[20]|  text_features[21]|   text_features[22]|   text_features[23]|   text_features[24]|independent_features|\n",
      "+-------------+-----------+--------------+------------+--------+------------+--------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+-------------------+-------------------+--------------------+-------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|          2.0|        0.0|           0.0|         0.0|     1.0|         0.0|       0|0.28481611609458923|0.21882453560829163| 0.06194785609841347|-0.3682086169719696|  0.262920618057251|0.21629296243190765|0.015426518395543098| -0.2468055635690689|-0.14578208327293396| 0.2106577306985855|0.24197855591773987|-0.08361523598432541|0.09170368313789368| 0.08617748320102692|0.026449576020240784|-0.05779039487242699| 0.2882993221282959|-0.08279384672641754|0.24426540732383728|  -0.150812566280365|-0.14580199122428894|0.07274134457111359| -0.2563191056251526| -0.2306952327489853|-0.18770168721675873|[2.0,0.0,0.0,0.0,...|\n",
      "|          0.0|        0.0|           0.0|         0.0|     1.0|         0.0|       0| 0.3195931315422058|0.19706468284130096| 0.03314067795872688|-0.3947567045688629|  0.254959374666214|0.23158355057239532|  0.0764976367354393|-0.20055817067623138|  -0.173841193318367| 0.2155158966779709|0.19657807052135468|-0.11714870482683182| 0.1662881076335907|0.005150272510945797|0.022258605808019638|-0.04357261583209038|0.26955804228782654|-0.12863390147686005|0.23878857493400574| -0.2516402006149292| -0.2215471863746643| 0.1429288536310196|-0.11087437719106674|-0.29234302043914795|-0.01104248687624...|[0.0,0.0,0.0,0.0,...|\n",
      "|          0.0|        0.0|           0.0|         0.0|     1.0|         0.0|       1|0.23851928114891052| 0.3076338768005371|-0.17653104662895203|-0.4448571503162384|0.30118119716644287|0.13110922276973724| -0.3086492717266083| -0.3066905736923218|-0.23639264702796936|  0.229669451713562|0.36899808049201965| 0.05970092490315437|0.41369596123695374| 0.04517611488699913|  0.0813835933804512|-0.24557499587535858| 0.3376389443874359|-0.15255285799503326| 0.2527042627334595|-0.07634289562702179|-0.15443871915340424|0.24032162129878998|-0.26816296577453613| -0.1997353583574295|-0.22694823145866394|[0.0,0.0,0.0,0.0,...|\n",
      "|          0.0|        0.0|           0.0|         0.0|     0.0|         0.0|       1| 0.3071625530719757| 0.3351825773715973| 0.02615254558622837|-0.5104542970657349| 0.4520227909088135| 0.3210863471031189|-0.07211942970752716|-0.36298614740371704|-0.20763109624385834| 0.1737855225801468| 0.3595540523529053|  0.0700894445180893| 0.3958490192890167|0.002104988088831...| 0.18845775723457336|-0.12626425921916962| 0.4183928668498993| -0.2482673078775406| 0.3011300563812256| -0.3574143648147583| -0.3362348973751068| 0.1778687834739685|  -0.410393625497818| -0.2662389874458313| -0.2741830050945282|[0.0,0.0,0.0,0.0,...|\n",
      "|          0.0|        0.0|           0.0|         0.0|     0.0|         0.0|       0|0.11412931233644485|0.18321862816810608| 0.04408733919262886|-0.2825126647949219|0.23409242928028107|0.09913039207458496|-0.11477749794721603|-0.28402358293533325|-0.13690543174743652|0.21081191301345825|0.27128884196281433|-0.06363134831190109|0.20326478779315948|-0.03854455798864...|-0.00718324538320303|-0.08286300301551819|0.24246828258037567|-0.14909617602825165|0.16618691384792328|-0.02547060512006...|-0.06141772866249...|0.19568780064582825|-0.26773884892463684| -0.2021598219871521|-0.11504159867763519|[0.0,0.0,0.0,0.0,...|\n",
      "+-------------+-----------+--------------+------------+--------+------------+--------+-------------------+-------------------+--------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+-------------------+-------------------+--------------------+-------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_updated_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e23008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unnecessary columns\n",
    "tweets_updated_df = tweets_updated_df.drop(*feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2357597d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299998 ['BotOrNot', 'independent_features']\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets_updated_df.collect()), tweets_updated_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e2840f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model\n",
    "def get2DenseLayeredModel(input_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_dim=input_dim))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(200))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7e8c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = tweets_updated_df.randomSplit([0.80, 0.20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53e55b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240077 59959\n"
     ]
    }
   ],
   "source": [
    "print(train_df.count(), test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3f4800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BotOrNot', 'independent_features'] ['BotOrNot', 'independent_features']\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns, test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b706490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features --> 'BotOrNot'\n",
    "X_train = train_df.drop('BotOrNot')\n",
    "y_train = train_df.select('BotOrNot')\n",
    "X_test = test_df.drop('BotOrNot')\n",
    "y_test = test_df.select('BotOrNot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7719551",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint\n",
    "print(len(X_train.collect()), len(y_train.collect()))\n",
    "print(len(X_test.collect()), len(y_test.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6780f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_nparray_list(df, column_name):\n",
    "    rows = df.select(column_name).collect()\n",
    "    lists = [x[column_name] for x in rows]\n",
    "    nparr = np.array(lists)\n",
    "    \n",
    "    return nparr\n",
    "\n",
    "X_train = to_nparray_list(X_train, 'independent_features')\n",
    "y_train = to_nparray_list(y_train, 'BotOrNot')\n",
    "X_test = to_nparray_list(X_test, 'independent_features')\n",
    "y_test = to_nparray_list(y_test, 'BotOrNot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f92665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml model train and validation\n",
    "model = get2DenseLayeredModel(31)\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          validation_data=(X_test, y_test))\n",
    "score, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edccb030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
